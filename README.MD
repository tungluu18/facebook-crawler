## Read Me (or not, that's ok)

Crawler is written using Scrapy to crawl uid of users have reacted to a page's posts.

#### Prerequisite
>pandas
>scrapy

#### How to use
Super easy, one and only command:
> python crawl_page.py [page_url] [filename] 

Result will be saved in the directory profiles/uid/[filename], welcome! (filename must be .csv)

Module crawl post on page was written based on [https://github.com/rugantio/fbcrawl](https://github.com/rugantio/fbcrawl), you may want to check it out and give a star :>
Enjoy crawling!!!